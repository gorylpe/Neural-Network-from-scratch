# Neural Network from scratch

> Spontaneous project mid-course Machine Learning Specialization by Andrew Ng to summarize knowledge.

The goal is to implement basic features as in TensorFlow including:
- dense layers
- inference
- 'linear', 'sigmoid', 'relu' activations
- numerically accurate loss binary crossentropy and mean squared error
- training witch mini-batches and gradient descent

Bonus:
- 'softmax' activation and numerically accurate sparse categorical crossentropy
- gradient descent with momentum or Adam optimizer

in `.NET` (and then in `Python`)


